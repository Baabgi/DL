import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train.reshape(-1, 28, 28, 1) / 255.0, x_test.reshape(-1, 28, 28, 1) / 255.0
y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)

def build_model(batch_norm=False):
    model = Sequential([Flatten(input_shape=(28, 28, 1))])
    for units in [128, 64]:
        model.add(Dense(units, activation='relu'))
        if batch_norm: model.add(BatchNormalization())
    model.add(Dense(10, activation='softmax'))
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

history_no_bn = build_model().fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))
history_bn = build_model(batch_norm=True).fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))

plt.figure(figsize=(12, 4))
for i, metric in enumerate(["accuracy", "loss"]):
    plt.subplot(1, 2, i + 1)
    plt.plot(history_no_bn.history[metric], label="Without BN")
    plt.plot(history_bn.history[metric], label="With BN")
    plt.title(metric.capitalize()), plt.xlabel("Epoch"), plt.legend()
plt.show()
